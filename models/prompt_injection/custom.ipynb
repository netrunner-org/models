{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m datasets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds_name \u001b[38;5;129;01min\u001b[39;00m datasets_to_use:\n\u001b[0;32m---> 13\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(ds_name)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ds:\n\u001b[1;32m     15\u001b[0m         datasets\u001b[38;5;241m.\u001b[39mappend(ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 1: Load datasets from Hugging Face\n",
    "print(\"Loading datasets...\")\n",
    "datasets_to_use = [\n",
    "    \"JasperLS/prompt-injections\",\n",
    "    \"rubend18/ChatGPT-Jailbreak-Prompts\",\n",
    "    \"deepset/prompt-injections\",\n",
    "    \"ahsanayub/malicious-prompts\"\n",
    "]\n",
    "\n",
    "# Load and concatenate\n",
    "datasets = []\n",
    "for ds_name in datasets_to_use:\n",
    "    ds = load_dataset(ds_name)\n",
    "    if \"train\" in ds:\n",
    "        datasets.append(ds[\"train\"])\n",
    "    else:\n",
    "        # If dataset doesn't have train/test split, just grab all\n",
    "        datasets.append(ds[list(ds.keys())[0]])\n",
    "\n",
    "# Unify the datasets into one\n",
    "dataset = concatenate_datasets(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenization\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Step 2: Preprocess â€” ensure binary labels (0 = safe, 1 = malicious)\n",
    "def normalize_labels(example):\n",
    "    if \"label\" in example:\n",
    "        example[\"label\"] = int(example[\"label\"] != 0)  # normalize to 0 or 1\n",
    "    else:\n",
    "        # Heuristic fallback if dataset uses 'malicious' bool or custom labels\n",
    "        example[\"label\"] = int(\"malicious\" in str(example.get(\"tag\", \"\")).lower() or\n",
    "                               \"jailbreak\" in example[\"text\"].lower())\n",
    "    return example\n",
    "\n",
    "def tokenize(example, tokenizer):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Tokenization\n",
    "dataset = dataset.map(normalize_labels)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Step 4: Split train/test and set format\n",
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load model for binary classification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "# Step 7: Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-malicious-prompt\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "\n",
    "# Step 8: Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Train!\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Evaluate\n",
    "print(\"Evaluating...\")\n",
    "predictions = trainer.predict(dataset[\"test\"])\n",
    "print(classification_report(dataset[\"test\"][\"label\"], np.argmax(predictions.predictions, axis=1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
